{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khaliso/thesis/blob/main/bert_classifier/classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e318cf24",
      "metadata": {
        "id": "e318cf24"
      },
      "source": [
        "Let's install and import some stuff first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "95880e6c",
      "metadata": {
        "id": "95880e6c",
        "outputId": "24c2d7b5-e5d5-4c7d-d4c8-6fb36eef0ed1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.22.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.5.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (5.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.2)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.25.11)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=d1726180471f63ef28810ce93229a54a0fb7b7aded83f45d7b4ff820d957e390\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220929150707)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.49.1)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (22.9.24)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.25.11)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install keras\n",
        "!pip install sklearn\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "2bcbb2fe",
      "metadata": {
        "id": "2bcbb2fe"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch\n",
        "import keras\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from functions import *\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75b6066f",
      "metadata": {
        "id": "75b6066f"
      },
      "source": [
        "### Preprocessing the data:\n",
        "\n",
        "This task used the dataset presented in: \n",
        "\n",
        "Pérez-Almendros, C., Anke, L. E., & Schockaert, S. (2020, December). Don’t Patronize Me! An Annotated Dataset with Patronizing and Condescending Language towards Vulnerable Communities. In Proceedings of the 28th International Conference on Computational Linguistics (pp. 5891-5902).\n",
        "\n",
        "To obtain the dataset, see https://docs.google.com/forms/d/e/1FAIpQLSe5KyzXgpnEOjS-Y6Gb8TTKiWxh4_qLuPL-NGiqKCyF41ALlg/viewform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "100d2c89",
      "metadata": {
        "id": "100d2c89"
      },
      "outputs": [],
      "source": [
        "# read in dataset and have a look at its properties\n",
        "\n",
        "dpm = pd.read_csv(\"dontpatronizeme_pcl.tsv\", sep=\"\\t\", header=2, names=[\"num\", \"par_id\", \"keyword\", \"country_code\", \"text\", \"label\"])\n",
        "\n",
        "# Labels 0 and 1 are non-patronizing, 2-4 are patronizing\n",
        "dpm[\"label\"].replace({1:0}, inplace=True)\n",
        "dpm[\"label\"].replace(to_replace=1, value=0, inplace=True)\n",
        "dpm[\"label\"].replace(to_replace=[2,3,4], value=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Alright, what does the data look like?\n",
        "\n",
        "dpm.head()"
      ],
      "metadata": {
        "id": "qUrwSbv9f4jD",
        "outputId": "7f56e404-5294-43a0-b162-6315c2d4a78d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "id": "qUrwSbv9f4jD",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   num      par_id    keyword country_code  \\\n",
              "0    1  @@24942188   hopeless           ph   \n",
              "1    2  @@21968160    migrant           gh   \n",
              "2    3  @@16584954  immigrant           ie   \n",
              "3    4   @@7811231   disabled           nz   \n",
              "4    5   @@1494111    refugee           ca   \n",
              "\n",
              "                                                text  label  \n",
              "0  We 're living in times of absolute insanity , ...      0  \n",
              "1  In Libya today , there are countless number of...      0  \n",
              "2  White House press secretary Sean Spicer said t...      0  \n",
              "3  Council customers only signs would be displaye...      0  \n",
              "4  \" Just like we received migrants fleeing El Sa...      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b101c0dd-5d53-4551-b9bb-cc86a4229531\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "      <th>par_id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>country_code</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>@@24942188</td>\n",
              "      <td>hopeless</td>\n",
              "      <td>ph</td>\n",
              "      <td>We 're living in times of absolute insanity , ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>@@21968160</td>\n",
              "      <td>migrant</td>\n",
              "      <td>gh</td>\n",
              "      <td>In Libya today , there are countless number of...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>@@16584954</td>\n",
              "      <td>immigrant</td>\n",
              "      <td>ie</td>\n",
              "      <td>White House press secretary Sean Spicer said t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>@@7811231</td>\n",
              "      <td>disabled</td>\n",
              "      <td>nz</td>\n",
              "      <td>Council customers only signs would be displaye...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>@@1494111</td>\n",
              "      <td>refugee</td>\n",
              "      <td>ca</td>\n",
              "      <td>\" Just like we received migrants fleeing El Sa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b101c0dd-5d53-4551-b9bb-cc86a4229531')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b101c0dd-5d53-4551-b9bb-cc86a4229531 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b101c0dd-5d53-4551-b9bb-cc86a4229531');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "5418b15d",
      "metadata": {
        "id": "5418b15d"
      },
      "outputs": [],
      "source": [
        "# We don't use any of the additional info\n",
        "dpm = dpm[[\"text\", \"label\"]]\n",
        "dpm.dropna(inplace=True)\n",
        "dpm.rename(columns={\"label\":\"labels\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "4465e926",
      "metadata": {
        "id": "4465e926",
        "outputId": "b819ffb1-5632-46c9-cfa3-f04e25122f4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.905183\n",
              "1    0.094817\n",
              "Name: labels, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "train, test = train_test_split(dpm, test_size=0.2, random_state=42, stratify=dpm[\"labels\"])\n",
        "train[\"labels\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db902a14",
      "metadata": {
        "id": "db902a14"
      },
      "source": [
        "The dataset is highly unbalanced. We will undersample the negative class to the size of the postive class for our initial classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "c5efd790",
      "metadata": {
        "id": "c5efd790",
        "outputId": "a81a431e-f847-44bb-fd1f-712fd09816cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-c7426bff04ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_balanced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_pcl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_np_undersampled\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_balanced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_balanced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# shuffling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrain_balanced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_data_undersampled.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'sampled'"
          ]
        }
      ],
      "source": [
        "train_np = train[train[\"labels\"] == 0]\n",
        "train_pcl = train[train[\"labels\"] == 1]\n",
        "\n",
        "train_np_undersampled = train_np.sample(train_pcl.shape[0])\n",
        "\n",
        "train_balanced = pd.concat([train_pcl, train_np_undersampled])\n",
        "train_balanced = train_balanced.sampled(frac=1) # shuffling\n",
        "\n",
        "train_balanced.to_csv(\"train_data_undersampled.csv\")\n",
        "train.to_csv(\"train_data.csv\") # we will need this later\n",
        "test.to_csv(\"val_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f945aa0",
      "metadata": {
        "id": "5f945aa0"
      },
      "source": [
        "### Loading the undersampled data as five 80:20 splits for cross-validation\n",
        "\n",
        "#### Code is based on Huggingface Trainer Dokumentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59ba432f",
      "metadata": {
        "id": "59ba432f"
      },
      "outputs": [],
      "source": [
        "vals_ds_bin, trains_ds_bin = load_and_tokenize_training_set(\"train_data_undersampled.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "354f8e51",
      "metadata": {
        "id": "354f8e51"
      },
      "source": [
        "Let's get to training! We can do five-fold cv to be sure about metric reliability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6acc8f7d",
      "metadata": {
        "id": "6acc8f7d"
      },
      "outputs": [],
      "source": [
        "metrics = {} \n",
        "\n",
        "for i in range(5):\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
        "    trainer = Trainer(model=model, args=training_args, train_dataset=trains_ds_bin[i], eval_dataset=vals_ds_bin[i], compute_metrics=compute_metrics)\n",
        "    trainer.train()\n",
        "    metrics[i] = trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efbc0f09",
      "metadata": {
        "id": "efbc0f09"
      },
      "source": [
        "Let's look at the metrics on our validation sets for the different folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "628cd399",
      "metadata": {
        "id": "628cd399"
      },
      "outputs": [],
      "source": [
        "metrics_df = pd.DataFrame.from_dict(metrics).transpose()\n",
        "metrics_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b36159f8",
      "metadata": {
        "id": "b36159f8"
      },
      "outputs": [],
      "source": [
        "#trainer.save_model(\"semeval_task4/model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15019f0c",
      "metadata": {
        "id": "15019f0c"
      },
      "source": [
        "### Testing Model Performance on our held back validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8be7dce",
      "metadata": {
        "id": "c8be7dce"
      },
      "outputs": [],
      "source": [
        "test = load_test_set(\"val_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3d8dc6d",
      "metadata": {
        "id": "a3d8dc6d"
      },
      "outputs": [],
      "source": [
        "#model = AutoModelForSequenceClassification.from_pretrained(\"semeval_task4/model\", local_files_only=True)\n",
        "#trainer = Trainer(model=model, args=training_args)\n",
        "\n",
        "y_pred = trainer.predict(test[\"train\"])\n",
        "compute_test_metrics(y_pred, 'binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f345e5dd",
      "metadata": {
        "id": "f345e5dd"
      },
      "source": [
        "we can look at the confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae12d9f2",
      "metadata": {
        "id": "ae12d9f2"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_pred.label_ids, y_pred.predictions.argmax(-1))\n",
        "show_confusion_matrix(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d9ca337",
      "metadata": {
        "id": "1d9ca337"
      },
      "source": [
        "### Classifying synthetic data with pre-classifier. We will only use those samples, which are classified as PCL by our classifier\n",
        "\n",
        "this step can be skipped in favor of using the already predicted datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abc89714",
      "metadata": {
        "id": "abc89714"
      },
      "outputs": [],
      "source": [
        "#model = AutoModelForSequenceClassification.from_pretrained(\"semeval_task4/model\", local_files_only=True)\n",
        "#trainer = Trainer(model=model, args=training_args)\n",
        "\n",
        "test = load_testset(\"synthetic_data/synthetic_npt_data.csv\") # generated as non-patronizing\n",
        "#test = load_testset(\"synthetic_data/synthetic_data.csv\") # generated as patronizing\n",
        "y_pred = trainer.predict(test[\"train\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "864eb21a",
      "metadata": {
        "id": "864eb21a"
      },
      "outputs": [],
      "source": [
        "# adding model predictions to the synthetic dataset\n",
        "synth = pd.read_csv(\"synthetic_npt_data.csv\")\n",
        "synth[\"labels\"] = y_pred.predictions.argmax(-1)\n",
        "synth.to_csv(\"predicted/synthetic_nonpatronizing_with_predictions_new.csv\")\n",
        "\n",
        "'''synth = pd.read_csv(\"synthetic_data.csv\")\n",
        "synth[\"labels\"] = y_pred.predictions.argmax(-1)\n",
        "synth.to_csv(\"predicted/synthetic_patronizing_with_predictions_new.csv\")'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd8040c1",
      "metadata": {
        "id": "cd8040c1"
      },
      "source": [
        "### Discarding all samples, where prediction and intention do not match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3487d1a",
      "metadata": {
        "id": "b3487d1a"
      },
      "outputs": [],
      "source": [
        "np = pd.read_csv(\"predicted/synthetic_nonpatronizing_with_predictions.csv\", index_col=[0])\n",
        "np_correct = np[np[\"labels\"] == 0]\n",
        "np_correct.to_csv(\"synthetic_npt_data_predicted.csv\")\n",
        "\n",
        "pcl = pd.read_csv(\"predicted/synthetic_patronizing_with_predictions.csv\", index_col=[0])\n",
        "pcl_correct = pcl[pcl[\"labels\"] == 1]\n",
        "pcl_correct.to_csv(\"synthetic_pcl_predicted.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5279ef5",
      "metadata": {
        "id": "c5279ef5"
      },
      "source": [
        "### Using prepared synthetic_dpm dataset to train the new classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3795a79",
      "metadata": {
        "id": "a3795a79"
      },
      "outputs": [],
      "source": [
        "synthetic = load_testset(\"synthetic_npt_data_predicted.csv\")\n",
        "#vals_ds_bin, trains_ds_bin = load_testset(\"synthetic_pcl_predicted.csv\")\n",
        "trains_ds_bin, vals_ds_bin = load_and_tokenize_trainingset(\"train_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b6c93af",
      "metadata": {
        "id": "8b6c93af"
      },
      "outputs": [],
      "source": [
        "metrics_synth = {}\n",
        "\n",
        "for i in range(5):\n",
        "    trains_ds_bin_enh = concatenate_datasets([synthetic[\"train\"], trains_ds_bin[i]])\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
        "    trainer = Trainer(model=model, args=training_args, train_dataset=trains_ds_bin_enh, eval_dataset=vals_ds_bin[i], compute_metrics=compute_metrics)\n",
        "    trainer.train()\n",
        "    metrics_synth[i] = trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63ff191a",
      "metadata": {
        "id": "63ff191a"
      },
      "outputs": [],
      "source": [
        "metrics_synth_df = pd.DataFrame.from_dict(metrics_synth).transpose()\n",
        "metrics_synth_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e0aeda8",
      "metadata": {
        "id": "6e0aeda8"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"dpmEnhanced/model\")\n",
        "#trainer.save_model(\"dpmEnhancedPos/model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fda2856c",
      "metadata": {
        "id": "fda2856c"
      },
      "source": [
        "### And evaluate performance on held-out test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e11b6df5",
      "metadata": {
        "id": "e11b6df5"
      },
      "outputs": [],
      "source": [
        "test = load_test_set(\"val_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adf49163",
      "metadata": {
        "id": "adf49163"
      },
      "outputs": [],
      "source": [
        "#model = AutoModelForSequenceClassification.from_pretrained(\"dpmEnhanced/model\", local_files_only=True)\n",
        "#trainer = Trainer(model=model, args=training_args)\n",
        "\n",
        "y_pred = trainer.predict(test[\"train\"])\n",
        "compute_test_metrics(y_pred, 'binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ada0db43",
      "metadata": {
        "id": "ada0db43"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_pred.label_ids, y_pred.predictions.argmax(-1))\n",
        "show_confusion_matrix(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e5801d3",
      "metadata": {
        "id": "0e5801d3"
      },
      "source": [
        "## We can now classify the test data\n",
        "To use the trainer.predict() method, we have created a new column \"labels\" in the .csv and filled it with 1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e801607b",
      "metadata": {
        "id": "e801607b"
      },
      "outputs": [],
      "source": [
        "#model = AutoModelForSequenceClassification.from_pretrained(\"dpmEnhanced/model\", local_files_only=True)\n",
        "#trainer = Trainer(model=model, args=training_args)\n",
        "\n",
        "test = load_test_set(\"test_dataset.csv\")\n",
        "y_pred = trainer.predict(test[\"train\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4987f1ce",
      "metadata": {
        "id": "4987f1ce"
      },
      "source": [
        "Get predictions and save them to a txt-file. We need one prediction per line. The resulting file can be zipped and submitted to https://competitions.codalab.org/competitions/34344#learn_the_details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a50a5a8",
      "metadata": {
        "id": "6a50a5a8"
      },
      "outputs": [],
      "source": [
        "preds = y_pred.predictions.argmax(-1)\n",
        "res = pd.DataFrame(preds)\n",
        "res.to_csv(\"task1.txt\", header=False, index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}