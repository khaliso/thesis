{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khaliso/thesis/blob/main/bert_classifier/classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e318cf24",
      "metadata": {
        "id": "e318cf24"
      },
      "source": [
        "Let's install and import some stuff first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95880e6c",
      "metadata": {
        "id": "95880e6c"
      },
      "outputs": [],
      "source": [
        "'''!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install keras\n",
        "!pip install tensorflow'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bcbb2fe",
      "metadata": {
        "id": "2bcbb2fe"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch\n",
        "import keras\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from functions import *\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75b6066f",
      "metadata": {
        "id": "75b6066f"
      },
      "source": [
        "### Preprocessing the data:\n",
        "\n",
        "This task used the dataset presented in: \n",
        "\n",
        "Pérez-Almendros, C., Anke, L. E., & Schockaert, S. (2020, December). Don’t Patronize Me! An Annotated Dataset with Patronizing and Condescending Language towards Vulnerable Communities. In Proceedings of the 28th International Conference on Computational Linguistics (pp. 5891-5902).\n",
        "\n",
        "To obtain the dataset, see https://docs.google.com/forms/d/e/1FAIpQLSe5KyzXgpnEOjS-Y6Gb8TTKiWxh4_qLuPL-NGiqKCyF41ALlg/viewform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "100d2c89",
      "metadata": {
        "id": "100d2c89"
      },
      "outputs": [],
      "source": [
        "# read in dataset and have a look at its properties\n",
        "\n",
        "dpm = pd.read_csv(\"dontpatronizeme_pcl.tsv\", sep=\"\\t\")\n",
        "\n",
        "# Labels 0 and 1 are non-patronizing, 2-4 are patronizing\n",
        "dpm[\"label\"].replace({1:0}, inplace=True)\n",
        "dpm[\"label\"].replace(to_replace=1, value=0, inplace=True)\n",
        "dpm[\"label\"].replace(to_replace=[2,3,4], value=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5418b15d",
      "metadata": {
        "id": "5418b15d"
      },
      "outputs": [],
      "source": [
        "# We don't use any of the additional info\n",
        "dpm = dpm[[\"text\", \"label\"]]\n",
        "dpm.dropna(inplace=True)\n",
        "dpm.rename(columns={\"label\":\"labels\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4465e926",
      "metadata": {
        "id": "4465e926"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(pcl, test_size=0.2, random_state=42, stratify=dpm[\"labels\"])\n",
        "train[\"labels\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db902a14",
      "metadata": {
        "id": "db902a14"
      },
      "source": [
        "The dataset is highly unbalanced. We will undersample the negative class to the size of the postive class for our initial classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5efd790",
      "metadata": {
        "id": "c5efd790"
      },
      "outputs": [],
      "source": [
        "train_np = train[train[\"labels\"] == 0]\n",
        "train_pcl = train[train[\"labels\"] == 1]\n",
        "\n",
        "train_np_undersampled = train_np.sample(train_pcl.shape[0])\n",
        "\n",
        "train_balanced = pd.concat([train_pcl, train_np_undersampled])\n",
        "train_balanced = train_balanced.sampled(frac=1) # shuffling\n",
        "\n",
        "train_balanced.to_csv(\"train_data_undersampled.csv\")\n",
        "train.to_csv(\"train_data.csv\") # we will need this later\n",
        "test.to_csv(\"val_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f945aa0",
      "metadata": {
        "id": "5f945aa0"
      },
      "source": [
        "### Loading the undersampled data as five 80:20 splits for cross-validation\n",
        "\n",
        "#### Code is based on Huggingface Trainer Dokumentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59ba432f",
      "metadata": {
        "id": "59ba432f"
      },
      "outputs": [],
      "source": [
        "vals_ds_bin, trains_ds_bin = load_and_tokenize_training_set(\"train_data_undersampled.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "354f8e51",
      "metadata": {
        "id": "354f8e51"
      },
      "source": [
        "Let's get to training! We can do five-fold cv to be sure about metric reliability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6acc8f7d",
      "metadata": {
        "id": "6acc8f7d"
      },
      "outputs": [],
      "source": [
        "metrics = {} \n",
        "\n",
        "for i in range(5):\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
        "    trainer = Trainer(model=model, args=training_args, train_dataset=trains_ds_bin[i], eval_dataset=vals_ds_bin[i], compute_metrics=compute_metrics)\n",
        "    trainer.train()\n",
        "    metrics[i] = trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efbc0f09",
      "metadata": {
        "id": "efbc0f09"
      },
      "source": [
        "Let's look at the metrics on our validation sets for the different folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "628cd399",
      "metadata": {
        "id": "628cd399"
      },
      "outputs": [],
      "source": [
        "metrics_df = pd.DataFrame.from_dict(metrics).transpose()\n",
        "metrics_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b36159f8",
      "metadata": {
        "id": "b36159f8"
      },
      "outputs": [],
      "source": [
        "#trainer.save_model(\"semeval_task4/model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15019f0c",
      "metadata": {
        "id": "15019f0c"
      },
      "source": [
        "### Testing Model Performance on our held back validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8be7dce",
      "metadata": {
        "id": "c8be7dce"
      },
      "outputs": [],
      "source": [
        "test = load_test_set(\"val_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3d8dc6d",
      "metadata": {
        "id": "a3d8dc6d"
      },
      "outputs": [],
      "source": [
        "#model = AutoModelForSequenceClassification.from_pretrained(\"semeval_task4/model\", local_files_only=True)\n",
        "#trainer = Trainer(model=model, args=training_args)\n",
        "\n",
        "y_pred = trainer.predict(test[\"train\"])\n",
        "compute_test_metrics(y_pred, 'binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f345e5dd",
      "metadata": {
        "id": "f345e5dd"
      },
      "source": [
        "we can look at the confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae12d9f2",
      "metadata": {
        "id": "ae12d9f2"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_pred.label_ids, y_pred.predictions.argmax(-1))\n",
        "show_confusion_matrix(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d9ca337",
      "metadata": {
        "id": "1d9ca337"
      },
      "source": [
        "### Classifying synthetic data with pre-classifier. We will only use those samples, which are classified as PCL by our classifier\n",
        "\n",
        "this step can be skipped in favor of using the already predicted datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abc89714",
      "metadata": {
        "id": "abc89714"
      },
      "outputs": [],
      "source": [
        "#model = AutoModelForSequenceClassification.from_pretrained(\"semeval_task4/model\", local_files_only=True)\n",
        "#trainer = Trainer(model=model, args=training_args)\n",
        "\n",
        "test = load_testset(\"synthetic_data/synthetic_npt_data.csv\") # generated as non-patronizing\n",
        "#test = load_testset(\"synthetic_data/synthetic_data.csv\") # generated as patronizing\n",
        "y_pred = trainer.predict(test[\"train\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "864eb21a",
      "metadata": {
        "id": "864eb21a"
      },
      "outputs": [],
      "source": [
        "# adding model predictions to the synthetic dataset\n",
        "synth = pd.read_csv(\"synthetic_npt_data.csv\")\n",
        "synth[\"labels\"] = y_pred.predictions.argmax(-1)\n",
        "synth.to_csv(\"predicted/synthetic_nonpatronizing_with_predictions_new.csv\")\n",
        "\n",
        "'''synth = pd.read_csv(\"synthetic_data.csv\")\n",
        "synth[\"labels\"] = y_pred.predictions.argmax(-1)\n",
        "synth.to_csv(\"predicted/synthetic_patronizing_with_predictions_new.csv\")'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd8040c1",
      "metadata": {
        "id": "cd8040c1"
      },
      "source": [
        "### Discarding all samples, where prediction and intention do not match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3487d1a",
      "metadata": {
        "id": "b3487d1a"
      },
      "outputs": [],
      "source": [
        "np = pd.read_csv(\"predicted/synthetic_nonpatronizing_with_predictions.csv\", index_col=[0])\n",
        "np_correct = np[np[\"labels\"] == 0]\n",
        "np_correct.to_csv(\"synthetic_npt_data_predicted.csv\")\n",
        "\n",
        "pcl = pd.read_csv(\"predicted/synthetic_patronizing_with_predictions.csv\", index_col=[0])\n",
        "pcl_correct = pcl[pcl[\"labels\"] == 1]\n",
        "pcl_correct.to_csv(\"synthetic_pcl_predicted.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5279ef5",
      "metadata": {
        "id": "c5279ef5"
      },
      "source": [
        "### Using prepared synthetic_dpm dataset to train the new classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3795a79",
      "metadata": {
        "id": "a3795a79"
      },
      "outputs": [],
      "source": [
        "synthetic = load_testset(\"synthetic_npt_data_predicted.csv\")\n",
        "#vals_ds_bin, trains_ds_bin = load_testset(\"synthetic_pcl_predicted.csv\")\n",
        "trains_ds_bin, vals_ds_bin = load_and_tokenize_trainingset(\"train_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b6c93af",
      "metadata": {
        "id": "8b6c93af"
      },
      "outputs": [],
      "source": [
        "metrics_synth = {}\n",
        "\n",
        "for i in range(5):\n",
        "    trains_ds_bin_enh = concatenate_datasets([synthetic[\"train\"], trains_ds_bin[i]])\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
        "    trainer = Trainer(model=model, args=training_args, train_dataset=trains_ds_bin_enh, eval_dataset=vals_ds_bin[i], compute_metrics=compute_metrics)\n",
        "    trainer.train()\n",
        "    metrics_synth[i] = trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63ff191a",
      "metadata": {
        "id": "63ff191a"
      },
      "outputs": [],
      "source": [
        "metrics_synth_df = pd.DataFrame.from_dict(metrics_synth).transpose()\n",
        "metrics_synth_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e0aeda8",
      "metadata": {
        "id": "6e0aeda8"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"dpmEnhanced/model\")\n",
        "#trainer.save_model(\"dpmEnhancedPos/model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fda2856c",
      "metadata": {
        "id": "fda2856c"
      },
      "source": [
        "### And evaluate performance on held-out test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e11b6df5",
      "metadata": {
        "id": "e11b6df5"
      },
      "outputs": [],
      "source": [
        "test = load_test_set(\"val_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adf49163",
      "metadata": {
        "id": "adf49163"
      },
      "outputs": [],
      "source": [
        "#model = AutoModelForSequenceClassification.from_pretrained(\"dpmEnhanced/model\", local_files_only=True)\n",
        "#trainer = Trainer(model=model, args=training_args)\n",
        "\n",
        "y_pred = trainer.predict(test[\"train\"])\n",
        "compute_test_metrics(y_pred, 'binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ada0db43",
      "metadata": {
        "id": "ada0db43"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_pred.label_ids, y_pred.predictions.argmax(-1))\n",
        "show_confusion_matrix(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e5801d3",
      "metadata": {
        "id": "0e5801d3"
      },
      "source": [
        "## We can now classify the test data\n",
        "To use the trainer.predict() method, we have created a new column \"labels\" in the .csv and filled it with 1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e801607b",
      "metadata": {
        "id": "e801607b"
      },
      "outputs": [],
      "source": [
        "#model = AutoModelForSequenceClassification.from_pretrained(\"dpmEnhanced/model\", local_files_only=True)\n",
        "#trainer = Trainer(model=model, args=training_args)\n",
        "\n",
        "test = load_test_set(\"test_dataset.csv\")\n",
        "y_pred = trainer.predict(test[\"train\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4987f1ce",
      "metadata": {
        "id": "4987f1ce"
      },
      "source": [
        "Get predictions and save them to a txt-file. We need one prediction per line. The resulting file can be zipped and submitted to https://competitions.codalab.org/competitions/34344#learn_the_details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a50a5a8",
      "metadata": {
        "id": "6a50a5a8"
      },
      "outputs": [],
      "source": [
        "preds = y_pred.predictions.argmax(-1)\n",
        "res = pd.DataFrame(preds)\n",
        "res.to_csv(\"task1.txt\", header=False, index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}